{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Vanilla Gradient**\n",
        "\n",
        "The Vanilla Gradient, first introduced by Simonyan et al. (2014), is the first and simplest gradient based interpretation method we are exploring. It's core concept is that if a small change to pixel $(i,j)$ has a large impact on the model's confidence in a class, that pixel is of high importance. In this project, we are using saliency maps to visualise pixel importance: the brighter the pixel, the more important it was in the CNN's classification decision.\n",
        "\n",
        "Assume we have an input image\n",
        "\n",
        "$x \\in [0,1]^{C \\times H \\times W}$,\n",
        "\n",
        " and our neural network is a function\n",
        "\n",
        "$f(x)=(f_1(x), f_2(x), \\dots, f_K(x))$,\n",
        "\n",
        "where $f_i(x)$ is the pre-softmax logit for class $i$ and we have $K$ classes.\n",
        "\n",
        "Then the model will predict class $c$ such that\n",
        "\n",
        "$c = argmax_{i \\in \\{1, \\dots, K\\}} f_i(x).$\n",
        "\n",
        "\\\n",
        "**Gradient Based Pixel Importance**\n",
        "\n",
        "To identify which pixels were used in prediction, Vanilla Gradient computes:\n",
        "\n",
        "$G(x) = \\frac{\\partial}{\\partial x}f_c(x) \\bigg|_{x=x_0} \\in â„œ^{C \\times H \\times W}$\n",
        "\n",
        "\n",
        "This is the Vanilla Gradient and each matrix entry $G_{c,i,j}(x)$ measures how sensitive the class score is to adjustments to pixel $(i,j)$ in channel $c$. We take the absoloute value, since a large magnitude gradient indicates that the pixel is influential in the CNN's decision regardless of direction.\n",
        "\n",
        "The raw gradient $G(x)$ has shape $(C,H,W)$ (channel, height, width), so to display our 2D Saliency map we need to reduce across channels to $(H,W)$.\n",
        "\n",
        "$S_{\\text{vanilla}}(i,j)=\\max_{c \\in \\{1, \\dots, K\\}}\\vert G(x)_{c,i,j}\\vert$\n",
        "\n",
        "Finally, we normalise to $[0,1]$ for visualisation in our saliency map:\n",
        "\n",
        "$S = \\frac{S - \\min(S)}{\\max(S) - \\min(S)}$.\n",
        "\n"
      ],
      "metadata": {
        "id": "TH80X13TNjiu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Insert image here\n",
        "\n"
      ],
      "metadata": {
        "id": "CXHMW7S-Tk4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vanilla Gradient Saliency Diagram**\n",
        "\n",
        "The figure above illustrates the Vanilla Gradient Saliency algorithm with an input image $X$.\n",
        "\n",
        "1) Forwards Pass:\n",
        "\n",
        "In the forwards pass, $x$ is passed though model $f(\\cdotp)$, producing the logit vector $f(x)$.\n",
        "\n",
        "2) Class Prediction:\n",
        "\n",
        "From $f(x)$, the model predicts the class with the maximum logit using argmax - here Maltese Dog.\n",
        "\n",
        "3) Backwards Pass:\n",
        "\n",
        "Here we backpropogate to compute the gradient of the predicted class score with respect to each input pixel, obtaining Gradient Matrix $G(x)$.\n",
        "\n",
        "4) Saliency Map:\n",
        "\n",
        "The final step is taking the absoloute value, reducing the channels and normalising to get our saliency map as seen in the bottom left corner."
      ],
      "metadata": {
        "id": "lU2PxJHFgVIS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ReLU Boundaries**\n",
        "\n",
        "Vanilla Gradient isn't recognised as the most powerful pixel attribution measure (hence why we will try SmoothGrad and GradCAM) - it's highly sensitive to small changes in input and therefore vulnerable to noise.\n",
        "\n",
        "This behaviour"
      ],
      "metadata": {
        "id": "L8jcZZs9cQS6"
      }
    }
  ]
}